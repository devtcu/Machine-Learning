{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4d67a3",
   "metadata": {},
   "source": [
    "Here I attempt to build a neural network from scratch without using pytorch or tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49583b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9f22b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mnist_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2c09383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() #shows preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89eec92",
   "metadata": {},
   "source": [
    "but working with numpy arrays works better so lets do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fc60fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "print(data.shape) #m is the number of digits examples we have in our dataset and n (or rather n-1, snce 1 coulkmn is for label name) is the number of pixels. For ref, look at the table above \n",
    "\n",
    "print(data[10039, 600]) #test out which image and pixel value you would like to see - here it is the 10039th image and its 600th pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c51b19",
   "metadata": {},
   "source": [
    "so our image has a collection 60000 randomized digits(rows) and 785 columns, each entry is a number that represents a pixel (28x28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa4076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 1000)\n"
     ]
    }
   ],
   "source": [
    "#wont train on this data, just for testing purposes\n",
    "data_dev = data[0:1000].T # lets take the first 1000 rows and transpose it - so now each column represents one image\n",
    "Y_dev = data_dev[0] #first row\n",
    "X_dev = data_dev[1:n] #disregards the label row and extracts only the pixel data\n",
    "X_dev = X_dev / 225.\n",
    "\n",
    "#the actual training data\n",
    "data_train = data[1000:m].T #rest of the data from the MNIST dataset from 1000th image\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 225.\n",
    "_,m_train = X_train.shape\n",
    "\n",
    "print(data_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b09b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[: , 0].shape #: means all rows, and 0 means the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4becf",
   "metadata": {},
   "source": [
    "now lets initialize all our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2ffc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    #weights and biases\n",
    "    w1 = np.random.rand(10, 784) - 0.5 #2d numpy array with 10 rows and 784 columns with random values bw 0 and 1\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    w2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    \n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb9807",
   "metadata": {},
   "source": [
    "Now let us make the forward propagation function - which is where we take in an image and get a prediction out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8a8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "   \n",
    "def softmax(z):\n",
    "    return np.exp(z) / sum(np.exp(z))\n",
    "\n",
    "def for_prop(w1, b1, w2, b2, x):\n",
    "    a0 = x\n",
    "    z1 = w1.dot(a0) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a9c48",
   "metadata": {},
   "source": [
    "Now for backward propagation - which is where we start with our prediction and find out how much it deviated from the label. This will allow us to optimize the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e229153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used in the function back_prop\n",
    "def relu_derivative(z):\n",
    "    return z > 0 #when returning a boolean, false is 0 and true is 1\n",
    "\n",
    "#used in the function back_prop\n",
    "def label_encode(y):\n",
    "    label_y = np.zeros((y.size, y.max() + 1))\n",
    "    label_y[np.arange(y.size), y] = 1\n",
    "    #and then lets flip it\n",
    "    label_y = label_y.T\n",
    "    return label_y\n",
    "\n",
    "def back_prop(z1, a1, z2, a2, w1, w2, x, y): #y is the labels - we need to hot encode it seperately above\n",
    "    label_y = label_encode(y)\n",
    "    dz2 = a2 - label_y\n",
    "    dw2 = (1 / m) * dz2.dot(a1.T)\n",
    "    db2 = (1 / m) * np.sum(dz2)\n",
    "    \n",
    "    dz1 = w2.T.dot(dz2) * relu_derivative(z1)\n",
    "    dw1 = (1 / m) * dz1.dot(x.T)\n",
    "    db1 = (1 / m) * np.sum(dz1)\n",
    "    \n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return w1, b1, w2, b2   \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac91216",
   "metadata": {},
   "source": [
    "So now we need some way of actually uses the gradients to update the weights and biases. Without it, the neural networks weights and biases cannot change and the model will not learn. So let us implement gradient descent. the first two functions are going to be something you have to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f1cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    print(predictions, y)\n",
    "    return np.sum(predictions == y) / y.size\n",
    "\n",
    "\n",
    "def grad_descent(x, y, iter, alpha):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    # now we run a loop through the iterations (epoch)\n",
    "    for i in range(iter):\n",
    "        #forward propagation\n",
    "        z1, a1, z2, a2 = for_prop(w1, b1, w2, b2, x)\n",
    "        #backward propagation\n",
    "        dw1, db1, dw2, db2 = back_prop(z1, a1, z2, a2, w1, w2, x, y)\n",
    "        #update the parameters\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        \n",
    "        if (i % 10 == 0):\n",
    "            print(\"Iteration: \", i)\n",
    "            print('Accuracy: ', get_accuracy(get_predictions(a2), y))\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7291faa",
   "metadata": {},
   "source": [
    "Now for the excting part - let's run gradient descent with our trainning data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8200c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 8 4 ... 8 0 0] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.06371186440677966\n",
      "Iteration:  10\n",
      "[6 8 7 ... 8 3 7] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.15710169491525425\n",
      "Iteration:  20\n",
      "[6 8 7 ... 8 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.2085593220338983\n",
      "Iteration:  30\n",
      "[7 3 7 ... 9 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.24864406779661016\n",
      "Iteration:  40\n",
      "[8 3 9 ... 9 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.28420338983050847\n",
      "Iteration:  50\n",
      "[8 3 9 ... 9 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.32093220338983053\n",
      "Iteration:  60\n",
      "[8 3 9 ... 9 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.36927118644067797\n",
      "Iteration:  70\n",
      "[8 3 9 ... 9 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.4322372881355932\n",
      "Iteration:  80\n",
      "[8 3 9 ... 7 3 9] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.48901694915254235\n",
      "Iteration:  90\n",
      "[1 3 9 ... 7 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.5346271186440678\n",
      "Iteration:  100\n",
      "[1 3 9 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.5695593220338983\n",
      "Iteration:  110\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.5987966101694915\n",
      "Iteration:  120\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.6239661016949153\n",
      "Iteration:  130\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.6449830508474577\n",
      "Iteration:  140\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.6635762711864407\n",
      "Iteration:  150\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.6794745762711865\n",
      "Iteration:  160\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.6937796610169491\n",
      "Iteration:  170\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.7062203389830508\n",
      "Iteration:  180\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.718271186440678\n",
      "Iteration:  190\n",
      "[1 3 8 ... 9 3 4] [1 8 8 ... 9 3 4]\n",
      "Accuracy:  0.73\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = grad_descent(X_train, Y_train, 200, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = for_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_dev[:, index, None]\n",
    "    prediction = make_predictions(X_dev[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_dev[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "444d7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(27, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db22a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
